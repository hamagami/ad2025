{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNW9WzHxCQyY6qBdeStpCTe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamagami/ad2025/blob/main/TransformerAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoWuDc_1UwOg"
      },
      "outputs": [],
      "source": [
        "# 1) ライブラリ\n",
        "import numpy as np, torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "np.random.seed(42); torch.manual_seed(42)\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) 合成データ\n",
        "#   正常: ch1 = 正弦波+雑音, ch2 = ch1の「長遅延コピー」+微小ノイズ（長期依存）\n",
        "#   異常: ch2 を独立ノイズにしたり、遅延を大きく狂わせる（長期依存の破壊）\n",
        "def make_pair_series(n=10000, delay=100, anomaly=False):\n",
        "    t = np.arange(n)\n",
        "    ch1 = 0.8*np.sin(2*np.pi*t/60) + 0.2*np.sin(2*np.pi*t/15) + 0.1*np.random.randn(n)\n",
        "    ch2 = np.zeros_like(ch1)\n",
        "    if not anomaly:\n",
        "        ch2[delay:] = ch1[:-delay] + 0.05*np.random.randn(n-delay)\n",
        "        ch2[:delay] = 0.05*np.random.randn(delay)\n",
        "    else:\n",
        "        ch2[:] = 0.6*np.random.randn(n)              # 関係を破壊\n",
        "        # 一部区間だけ遅延をズラす（より難しい異常）\n",
        "        for s in np.random.choice(np.arange(500, n-500), size=5, replace=False):\n",
        "            d = delay + np.random.randint(-40, 40)\n",
        "            L = np.random.randint(150, 250)\n",
        "            e = min(n, s+L)\n",
        "            ch2[s:e] = 0\n",
        "            segL = min(e-s, n-d)\n",
        "            if segL>0:\n",
        "                ch2[s:s+segL] = ch1[d:d+segL] + 0.05*np.random.randn(segL)\n",
        "    X = np.stack([ch1, ch2], axis=-1)   # shape: (n, 2)\n",
        "    return X\n",
        "\n",
        "N_TRAIN, N_VAL, N_TEST = 12000, 6000, 12000\n",
        "DELAY = 100\n",
        "\n",
        "train_ts = make_pair_series(N_TRAIN, delay=DELAY, anomaly=False)  # 正常のみ\n",
        "val_ts   = make_pair_series(N_VAL,   delay=DELAY, anomaly=False)  # 閾値用 正常\n",
        "test_ts  = make_pair_series(N_TEST,  delay=DELAY, anomaly=True)   # 異常あり\n"
      ],
      "metadata": {
        "id": "1QIgSwWBU0rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) スライディングウィンドウ化\n",
        "def to_windows(X, seq_len=256, stride=1):\n",
        "    L = len(X)\n",
        "    out = []\n",
        "    for i in range(0, L-seq_len+1, stride):\n",
        "        out.append(X[i:i+seq_len])\n",
        "    return np.array(out)  # (N, L, C)\n",
        "\n",
        "SEQ_LEN, STRIDE = 256, 1\n",
        "X_train = to_windows(train_ts, SEQ_LEN, STRIDE)\n",
        "X_val   = to_windows(val_ts,   SEQ_LEN, STRIDE)\n",
        "X_test  = to_windows(test_ts,  SEQ_LEN, STRIDE)\n",
        "\n",
        "# テストの窓ラベル（ざっくり）: ch2 と ch1のdelay整合が崩れているかの粗い指標\n",
        "# 相関を使って擬似ラベル（教材用の簡易ラベリング）\n",
        "def window_anom_label(w, delay=DELAY, tol=0.2):\n",
        "    x1 = w[:,0]; x2 = w[:,1]\n",
        "    if len(x1) <= delay+5: return 1\n",
        "    r = np.corrcoef(x1[:-delay], x2[delay:])[0,1]\n",
        "    return int(r < 0.6)  # 相関が低ければ異常\n",
        "\n",
        "y_test = np.array([window_anom_label(w, delay=DELAY) for w in X_test])\n",
        "\n",
        "X_train.shape, X_val.shape, X_test.shape, y_test.mean()\n"
      ],
      "metadata": {
        "id": "8y-40-alU793"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) DataLoader\n",
        "def tensor_ds(X):\n",
        "    X = torch.tensor(X, dtype=torch.float32)\n",
        "    return TensorDataset(X, X)\n",
        "train_loader = DataLoader(tensor_ds(X_train), batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(tensor_ds(X_val),   batch_size=64, shuffle=False)\n",
        "test_loader  = DataLoader(tensor_ds(X_test),  batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "9QPwZJUQU92k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) LSTM-AE（ベースライン）：2変量時系列\n",
        "class LSTMAE(nn.Module):\n",
        "    def __init__(self, in_dim=2, hid=128, lat=64, layers=1):\n",
        "        super().__init__()\n",
        "        self.enc = nn.LSTM(input_size=in_dim, hidden_size=hid, num_layers=layers, batch_first=True)\n",
        "        self.h2z = nn.Linear(hid, lat)\n",
        "        self.z2h = nn.Linear(lat, hid)\n",
        "        self.dec = nn.LSTM(input_size=in_dim, hidden_size=hid, num_layers=layers, batch_first=True)\n",
        "        self.out = nn.Linear(hid, in_dim)\n",
        "    def forward(self, x):\n",
        "        _, (h, c) = self.enc(x)\n",
        "        z = torch.relu(self.h2z(h[-1]))\n",
        "        h0 = torch.relu(self.z2h(z)).unsqueeze(0)\n",
        "        c0 = torch.zeros_like(h0)\n",
        "        y, _ = self.dec(x, (h0, c0))  # Teacher forcing: 入力xで条件づけ\n",
        "        return self.out(y)\n",
        "\n",
        "lstm = LSTMAE().to(device)\n"
      ],
      "metadata": {
        "id": "QjaBrQvxU_6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Transformer-AE：自己注意で長距離依存を直接参照（エンコーダ型AE）\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pos = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:,0::2] = torch.sin(pos*div)\n",
        "        pe[:,1::2] = torch.cos(pos*div)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))  # (1, L, d_model)\n",
        "    def forward(self, x):\n",
        "        L = x.size(1)\n",
        "        return x + self.pe[:,:L,:]\n",
        "\n",
        "class TransformerAE(nn.Module):\n",
        "    def __init__(self, in_dim=2, d_model=64, nhead=4, num_layers=3, dim_ff=128, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.in_proj  = nn.Linear(in_dim, d_model)\n",
        "        self.pos      = PositionalEncoding(d_model)\n",
        "        enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n",
        "                                               dim_feedforward=dim_ff, dropout=dropout, batch_first=True)\n",
        "        self.encoder  = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
        "        # デコーダ相当は「エンコーダ出力をそのまま再構成」にする（同長）\n",
        "        self.out_proj = nn.Linear(d_model, in_dim)\n",
        "    def forward(self, x):\n",
        "        h = self.in_proj(x)\n",
        "        h = self.pos(h)\n",
        "        z = self.encoder(h)\n",
        "        y = self.out_proj(z)\n",
        "        return y\n",
        "\n",
        "trf = TransformerAE().to(device)\n"
      ],
      "metadata": {
        "id": "NNuL7vBwVBRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Transformer-AE：自己注意で長距離依存を直接参照（エンコーダ型AE）\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pos = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:,0::2] = torch.sin(pos*div)\n",
        "        pe[:,1::2] = torch.cos(pos*div)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))  # (1, L, d_model)\n",
        "    def forward(self, x):\n",
        "        L = x.size(1)\n",
        "        return x + self.pe[:,:L,:]\n",
        "\n",
        "class TransformerAE(nn.Module):\n",
        "    def __init__(self, in_dim=2, d_model=64, nhead=4, num_layers=3, dim_ff=128, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.in_proj  = nn.Linear(in_dim, d_model)\n",
        "        self.pos      = PositionalEncoding(d_model)\n",
        "        enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n",
        "                                               dim_feedforward=dim_ff, dropout=dropout, batch_first=True)\n",
        "        self.encoder  = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
        "        # デコーダ相当は「エンコーダ出力をそのまま再構成」にする（同長）\n",
        "        self.out_proj = nn.Linear(d_model, in_dim)\n",
        "    def forward(self, x):\n",
        "        h = self.in_proj(x)\n",
        "        h = self.pos(h)\n",
        "        z = self.encoder(h)\n",
        "        y = self.out_proj(z)\n",
        "        return y\n",
        "\n",
        "trf = TransformerAE().to(device)\n"
      ],
      "metadata": {
        "id": "YOo5Y5RQVC__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) 学習ユーティリティ\n",
        "def train_ae(model, train_loader, val_loader, epochs=15, lr=1e-3):\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "    crit = nn.MSELoss()\n",
        "    best = np.inf\n",
        "    for ep in range(epochs):\n",
        "        model.train(); tr=0\n",
        "        for xb,_ in train_loader:\n",
        "            xb = xb.to(device)\n",
        "            opt.zero_grad()\n",
        "            recon = model(xb)\n",
        "            loss = crit(recon, xb)\n",
        "            loss.backward(); opt.step()\n",
        "            tr += loss.item()\n",
        "        model.eval(); va=0\n",
        "        with torch.no_grad():\n",
        "            for xb,_ in val_loader:\n",
        "                xb = xb.to(device)\n",
        "                va += crit(model(xb), xb).item()\n",
        "        print(f\"epoch {ep+1}/{epochs}  train={tr/len(train_loader):.5f}  val={va/len(val_loader):.5f}\")\n",
        "        best = min(best, va/len(val_loader))\n",
        "    return best\n",
        "\n",
        "print(\"=== Train LSTM-AE ===\")\n",
        "train_ae(lstm, train_loader, val_loader, epochs=15, lr=1e-3)\n",
        "print(\"=== Train Transformer-AE ===\")\n",
        "train_ae(trf,  train_loader, val_loader, epochs=15, lr=1e-3)\n"
      ],
      "metadata": {
        "id": "PFSu7-EPVEv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) 窓スコア（MSE）と閾値（検証95%点）\n",
        "@torch.no_grad()\n",
        "def window_scores(model, loader):\n",
        "    model.eval(); scores=[]\n",
        "    for xb,_ in loader:\n",
        "        xb = xb.to(device)\n",
        "        xh = model(xb)\n",
        "        mse = torch.mean((xb - xh)**2, dim=(1,2))\n",
        "        scores.append(mse.cpu().numpy())\n",
        "    return np.concatenate(scores)\n",
        "\n",
        "lstm_val = window_scores(lstm, val_loader)\n",
        "trf_val  = window_scores(trf,  val_loader)\n",
        "lstm_tst = window_scores(lstm, test_loader)\n",
        "trf_tst  = window_scores(trf,  test_loader)\n",
        "\n",
        "thr_lstm = np.percentile(lstm_val, 95)\n",
        "thr_trf  = np.percentile(trf_val,  95)\n",
        "\n",
        "pred_lstm = (lstm_tst > thr_lstm).astype(int)\n",
        "pred_trf  = (trf_tst  > thr_trf ).astype(int)\n"
      ],
      "metadata": {
        "id": "dx93FC9KVGlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9) 評価（擬似ラベル y_test を使用）\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "def evaluate(name, val_scores, tst_scores, y):\n",
        "    thr = np.percentile(val_scores, 95)\n",
        "    y_pred = (tst_scores > thr).astype(int)\n",
        "    auc = roc_auc_score(y, tst_scores)\n",
        "    ap  = average_precision_score(y, tst_scores)\n",
        "    tpr = np.mean(tst_scores[y==1] > thr)    # 検出率\n",
        "    fpr = np.mean(tst_scores[y==0] > thr)    # 誤警報率\n",
        "    print(f\"{name}: ROC-AUC={auc:.3f}  PR-AUC={ap:.3f}  Thr={thr:.4g}  TPR={tpr:.3f}  FPR={fpr:.3f}\")\n",
        "\n",
        "evaluate(\"LSTM-AE\", lstm_val, lstm_tst, y_test)\n",
        "evaluate(\"Transformer-AE\", trf_val, trf_tst, y_test)\n"
      ],
      "metadata": {
        "id": "iLAJBZgaVIR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10) 可視化（スコア分布と例）\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(lstm_tst[y_test==0], bins=50, alpha=0.6, label=\"Normal\")\n",
        "plt.hist(lstm_tst[y_test==1], bins=50, alpha=0.6, label=\"Anomaly\")\n",
        "plt.axvline(thr_lstm, color='r', linestyle='--'); plt.title(\"LSTM-AE scores\"); plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(trf_tst[y_test==0], bins=50, alpha=0.6, label=\"Normal\")\n",
        "plt.hist(trf_tst[y_test==1], bins=50, alpha=0.6, label=\"Anomaly\")\n",
        "plt.axvline(thr_trf, color='r', linestyle='--'); plt.title(\"Transformer-AE scores\"); plt.legend()\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "# 異常窓の復元例\n",
        "@torch.no_grad()\n",
        "def show_example(model, X, idx, title):\n",
        "    xb = torch.tensor(X[idx:idx+1], dtype=torch.float32).to(device)\n",
        "    xh = model(xb).cpu().numpy()[0]  # (L,2)\n",
        "    x  = X[idx]                      # (L,2)\n",
        "    fig,ax = plt.subplots(2,1,figsize=(10,4), sharex=True)\n",
        "    ax[0].plot(x[:,0], label='ch1'); ax[0].plot(xh[:,0], label='recon'); ax[0].set_title(title+\" ch1\"); ax[0].legend()\n",
        "    ax[1].plot(x[:,1], label='ch2'); ax[1].plot(xh[:,1], label='recon'); ax[1].set_title(title+\" ch2\"); ax[1].legend()\n",
        "    plt.show()\n",
        "\n",
        "# 代表的に異常と判定された窓のインデックスを一個ピック\n",
        "anom_idx_trf = np.where(pred_trf==1)[0]\n",
        "anom_idx_lstm= np.where(pred_lstm==1)[0]\n",
        "if len(anom_idx_trf)>0: show_example(trf,  X_test, anom_idx_trf[0],  \"Transformer-AE anomaly example\")\n",
        "if len(anom_idx_lstm)>0: show_example(lstm, X_test, anom_idx_lstm[0], \"LSTM-AE anomaly example\")\n"
      ],
      "metadata": {
        "id": "jCvq3rRyVKji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TfBu2aLxVMYD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}